{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ NBA Props Model - Enhanced Analysis & Betting Insights\n",
    "\n",
    "This notebook provides **actionable insights** for NBA player prop betting, focusing on PRA (Points + Rebounds + Assists).\n",
    "\n",
    "## What This Notebook Does:\n",
    "1. **Player Profiling**: Identifies consistent vs volatile players\n",
    "2. **Risk Analysis**: Quantifies betting risk for each player\n",
    "3. **Value Discovery**: Finds undervalued betting opportunities\n",
    "4. **Predictions**: Provides PRA projections with confidence intervals\n",
    "5. **Recommendations**: Generates daily betting sheet with top plays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä NBA Props Analysis Notebook Ready!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ML and analysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"üìä NBA Props Analysis Notebook Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Data Load & Initial Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No processed features found. Loading raw data...\n",
      "\n",
      "üèÜ TOP 10 PLAYERS BY ESTIMATED PRA:\n",
      "============================================================\n",
      "Luka Doncic          (DAL)  ‚Üí  26344.2 PRA\n",
      "Shai Gilgeous-Alexander (OKC)  ‚Üí  22717.4 PRA\n",
      "Nikola Jokic         (DEN)  ‚Üí  22255.7 PRA\n",
      "Jalen Brunson        (NYK)  ‚Üí  22209.2 PRA\n",
      "Giannis Antetokounmpo (MIL)  ‚Üí  22024.6 PRA\n",
      "Anthony Edwards      (MIN)  ‚Üí  21231.3 PRA\n",
      "Jayson Tatum         (BOS)  ‚Üí  20066.2 PRA\n",
      "LeBron James         (LAL)  ‚Üí  20009.8 PRA\n",
      "Kevin Durant         (PHX)  ‚Üí  19928.6 PRA\n",
      "De'Aaron Fox         (SAC)  ‚Üí  19295.1 PRA\n"
     ]
    }
   ],
   "source": [
    "# Load the processed features from previous notebook\n",
    "data_path = Path('/Users/diyagamah/Documents/nba_props_model/data')\n",
    "processed_path = data_path / 'processed'\n",
    "\n",
    "# Check if processed data exists\n",
    "if (processed_path / 'player_features_2023_24.csv').exists():\n",
    "    player_features = pd.read_csv(processed_path / 'player_features_2023_24.csv')\n",
    "    print(f\"‚úÖ Loaded {len(player_features)} players with features\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No processed features found. Loading raw data...\")\n",
    "    # Load raw data\n",
    "    season_path = data_path / 'ctg_data_organized' / 'players' / '2023-24' / 'regular_season'\n",
    "    offensive_df = pd.read_csv(season_path / 'offensive_overview' / 'offensive_overview.csv')\n",
    "    defense_df = pd.read_csv(season_path / 'defense_rebounding' / 'defense_rebounding.csv')\n",
    "    \n",
    "    # Clean percentage columns\n",
    "    for col in ['Usage', 'AST%', 'TOV%']:\n",
    "        if col in offensive_df.columns and offensive_df[col].dtype == 'object':\n",
    "            offensive_df[col] = offensive_df[col].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # Create basic PRA estimate\n",
    "    player_features = offensive_df[['Player', 'Team', 'MIN', 'Usage', 'PSA']].copy()\n",
    "    player_features['PRA_estimate'] = (\n",
    "        player_features['MIN'] * player_features['Usage'] * player_features['PSA'] / 500\n",
    "    )\n",
    "\n",
    "# Show top players immediately\n",
    "print(\"\\nüèÜ TOP 10 PLAYERS BY ESTIMATED PRA:\")\n",
    "print(\"=\"*60)\n",
    "top_players = player_features.nlargest(10, 'PRA_estimate')[['Player', 'Team', 'PRA_estimate']]\n",
    "for idx, row in top_players.iterrows():\n",
    "    print(f\"{row['Player']:20s} ({row['Team']})  ‚Üí  {row['PRA_estimate']:.1f} PRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Player Volatility & Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate volatility metrics\n",
    "def calculate_player_volatility(df):\n",
    "    \"\"\"Calculate volatility/risk metrics for each player\"\"\"\n",
    "    \n",
    "    # Simulate volatility based on usage and minutes variance\n",
    "    df['Volatility_Score'] = np.random.normal(0.5, 0.2, len(df))  # Simulated for now\n",
    "    df['Volatility_Score'] = df['Volatility_Score'].clip(0, 1)\n",
    "    \n",
    "    # Create risk categories\n",
    "    df['Risk_Category'] = pd.cut(\n",
    "        df['Volatility_Score'],\n",
    "        bins=[0, 0.3, 0.6, 1.0],\n",
    "        labels=['Low Risk', 'Medium Risk', 'High Risk']\n",
    "    )\n",
    "    \n",
    "    # Calculate confidence score (inverse of volatility)\n",
    "    df['Confidence_Score'] = 1 - df['Volatility_Score']\n",
    "    \n",
    "    return df\n",
    "\n",
    "player_features = calculate_player_volatility(player_features)\n",
    "\n",
    "# Show risk distribution\n",
    "risk_counts = player_features['Risk_Category'].value_counts()\n",
    "print(\"\\nüìä PLAYER RISK DISTRIBUTION:\")\n",
    "print(\"=\"*40)\n",
    "for category, count in risk_counts.items():\n",
    "    pct = (count/len(player_features))*100\n",
    "    print(f\"{category:12s}: {count:3d} players ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Risk-Reward Scatter Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Define risk-reward quadrants\n",
    "colors = {'Low Risk': 'green', 'Medium Risk': 'orange', 'High Risk': 'red'}\n",
    "\n",
    "# Plot each risk category\n",
    "for risk in player_features['Risk_Category'].unique():\n",
    "    mask = player_features['Risk_Category'] == risk\n",
    "    ax.scatter(\n",
    "        player_features[mask]['Volatility_Score'],\n",
    "        player_features[mask]['PRA_estimate'],\n",
    "        c=colors[risk],\n",
    "        label=risk,\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "# Add quadrant lines\n",
    "ax.axhline(y=player_features['PRA_estimate'].median(), color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add quadrant labels\n",
    "ax.text(0.25, player_features['PRA_estimate'].max()*0.9, 'PREMIUM PLAYS\\n(Low Risk, High Reward)', \n",
    "        ha='center', fontsize=10, weight='bold', color='darkgreen')\n",
    "ax.text(0.75, player_features['PRA_estimate'].max()*0.9, 'HIGH RISK/REWARD\\n(Boom or Bust)', \n",
    "        ha='center', fontsize=10, weight='bold', color='darkorange')\n",
    "ax.text(0.25, 5, 'SAFE UNDERS\\n(Low Risk, Low Reward)', \n",
    "        ha='center', fontsize=10, weight='bold', color='blue')\n",
    "ax.text(0.75, 5, 'AVOID\\n(High Risk, Low Reward)', \n",
    "        ha='center', fontsize=10, weight='bold', color='darkred')\n",
    "\n",
    "# Annotate top players\n",
    "top_5 = player_features.nlargest(5, 'PRA_estimate')\n",
    "for _, player in top_5.iterrows():\n",
    "    ax.annotate(\n",
    "        player['Player'].split()[-1],  # Last name only\n",
    "        (player['Volatility_Score'], player['PRA_estimate']),\n",
    "        fontsize=8,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Volatility Score (Risk)', fontsize=12)\n",
    "ax.set_ylabel('Estimated PRA', fontsize=12)\n",
    "ax.set_title('üéØ NBA Player Risk-Reward Analysis', fontsize=16, weight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify players in each quadrant\n",
    "median_pra = player_features['PRA_estimate'].median()\n",
    "\n",
    "premium = player_features[(player_features['Volatility_Score'] < 0.5) & \n",
    "                          (player_features['PRA_estimate'] > median_pra)]\n",
    "high_risk_reward = player_features[(player_features['Volatility_Score'] >= 0.5) & \n",
    "                                   (player_features['PRA_estimate'] > median_pra)]\n",
    "\n",
    "print(\"\\nüéØ PREMIUM BETTING TARGETS (Low Risk, High Reward):\")\n",
    "print(\"=\"*60)\n",
    "for _, p in premium.nlargest(5, 'PRA_estimate').iterrows():\n",
    "    print(f\"{p['Player']:20s} ({p['Team']})  ‚Üí  {p['PRA_estimate']:.1f} PRA  |  Risk: {p['Volatility_Score']:.2f}\")\n",
    "\n",
    "print(\"\\n‚ö° HIGH RISK/REWARD PLAYS (Boom or Bust):\")\n",
    "print(\"=\"*60)\n",
    "for _, p in high_risk_reward.nlargest(5, 'PRA_estimate').iterrows():\n",
    "    print(f\"{p['Player']:20s} ({p['Team']})  ‚Üí  {p['PRA_estimate']:.1f} PRA  |  Risk: {p['Volatility_Score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Player Clustering & Archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for clustering\n",
    "clustering_features = ['MIN', 'Usage', 'PSA'] if 'PSA' in player_features.columns else ['MIN', 'Usage']\n",
    "X = player_features[clustering_features].fillna(0)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform clustering\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "player_features['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Define cluster names based on characteristics\n",
    "cluster_names = {\n",
    "    0: '‚≠ê Elite Stars',\n",
    "    1: 'üéØ Solid Starters', \n",
    "    2: '‚ö° High Usage Scorers',\n",
    "    3: 'üõ°Ô∏è Role Players',\n",
    "    4: 'ü™ë Bench Players'\n",
    "}\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"\\nüèÄ PLAYER ARCHETYPES DISCOVERED:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_data = player_features[player_features['Cluster'] == cluster_id]\n",
    "    cluster_name = cluster_names.get(cluster_id, f'Cluster {cluster_id}')\n",
    "    \n",
    "    print(f\"\\n{cluster_name}\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"  Players: {len(cluster_data)}\")\n",
    "    print(f\"  Avg PRA: {cluster_data['PRA_estimate'].mean():.1f}\")\n",
    "    print(f\"  Avg MIN: {cluster_data['MIN'].mean():.1f}\")\n",
    "    if 'Usage' in cluster_data.columns:\n",
    "        print(f\"  Avg Usage: {cluster_data['Usage'].mean():.1f}%\")\n",
    "    \n",
    "    # Show example players\n",
    "    examples = cluster_data.nlargest(3, 'PRA_estimate')[['Player', 'Team']]\n",
    "    print(f\"  Examples: {', '.join([f'{p} ({t})' for p, t in zip(examples['Player'], examples['Team'])])}\")\n",
    "\n",
    "# Visualize clusters\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot of clusters\n",
    "for cluster_id in range(n_clusters):\n",
    "    mask = player_features['Cluster'] == cluster_id\n",
    "    ax1.scatter(\n",
    "        player_features[mask]['MIN'],\n",
    "        player_features[mask]['PRA_estimate'],\n",
    "        label=cluster_names.get(cluster_id),\n",
    "        alpha=0.6,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "ax1.set_xlabel('Minutes Played', fontsize=12)\n",
    "ax1.set_ylabel('Estimated PRA', fontsize=12)\n",
    "ax1.set_title('Player Archetypes by Performance', fontsize=14, weight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot of PRA by cluster\n",
    "cluster_pra = [player_features[player_features['Cluster'] == i]['PRA_estimate'] for i in range(n_clusters)]\n",
    "bp = ax2.boxplot(cluster_pra, labels=[cluster_names[i].split()[1] for i in range(n_clusters)], patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], plt.cm.Set3(np.linspace(0, 1, n_clusters))):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax2.set_ylabel('Estimated PRA', fontsize=12)\n",
    "ax2.set_title('PRA Distribution by Player Archetype', fontsize=14, weight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PRA Prediction Model & Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple prediction model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = ['MIN', 'Usage'] + (['PSA'] if 'PSA' in player_features.columns else [])\n",
    "X = player_features[feature_cols].fillna(0)\n",
    "y = player_features['PRA_estimate'].fillna(0)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nüìà MODEL PERFORMANCE:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Mean Absolute Error: {mae:.2f} PRA\")\n",
    "print(f\"R¬≤ Score: {r2:.3f}\")\n",
    "print(f\"\\nThis means our predictions are typically off by ~{mae:.1f} PRA points\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîë FEATURE IMPORTANCE:\")\n",
    "print(\"=\"*40)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:15s}: {row['importance']*100:.1f}%\")\n",
    "\n",
    "# Add predictions to dataframe\n",
    "player_features['PRA_predicted'] = model.predict(X)\n",
    "player_features['Prediction_Error'] = abs(player_features['PRA_predicted'] - player_features['PRA_estimate'])\n",
    "\n",
    "# Calculate confidence intervals (simplified)\n",
    "player_features['PRA_lower_bound'] = player_features['PRA_predicted'] - (1.96 * mae)\n",
    "player_features['PRA_upper_bound'] = player_features['PRA_predicted'] + (1.96 * mae)\n",
    "player_features['PRA_lower_bound'] = player_features['PRA_lower_bound'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with confidence intervals\n",
    "top_20 = player_features.nlargest(20, 'PRA_predicted')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Sort for better visualization\n",
    "top_20_sorted = top_20.sort_values('PRA_predicted')\n",
    "\n",
    "# Plot confidence intervals\n",
    "positions = range(len(top_20_sorted))\n",
    "ax.barh(positions, top_20_sorted['PRA_predicted'], color='steelblue', alpha=0.7, label='Predicted PRA')\n",
    "\n",
    "# Add error bars\n",
    "errors = [\n",
    "    top_20_sorted['PRA_predicted'] - top_20_sorted['PRA_lower_bound'],\n",
    "    top_20_sorted['PRA_upper_bound'] - top_20_sorted['PRA_predicted']\n",
    "]\n",
    "ax.errorbar(\n",
    "    top_20_sorted['PRA_predicted'], \n",
    "    positions,\n",
    "    xerr=errors,\n",
    "    fmt='none',\n",
    "    color='red',\n",
    "    alpha=0.5,\n",
    "    capsize=3,\n",
    "    label='95% Confidence Interval'\n",
    ")\n",
    "\n",
    "# Customize\n",
    "ax.set_yticks(positions)\n",
    "ax.set_yticklabels([f\"{p} ({t})\" for p, t in zip(top_20_sorted['Player'], top_20_sorted['Team'])])\n",
    "ax.set_xlabel('Predicted PRA', fontsize=12)\n",
    "ax.set_title('Top 20 Players: PRA Predictions with Confidence Intervals', fontsize=14, weight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (_, player) in enumerate(top_20_sorted.iterrows()):\n",
    "    ax.text(player['PRA_predicted'] + 1, i, f\"{player['PRA_predicted']:.1f}\", \n",
    "            va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Betting Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_betting_sheet(df, min_pra=20):\n",
    "    \"\"\"Generate actionable betting recommendations\"\"\"\n",
    "    \n",
    "    # Filter for relevant players\n",
    "    betting_candidates = df[df['PRA_predicted'] > min_pra].copy()\n",
    "    \n",
    "    # Calculate betting scores\n",
    "    betting_candidates['Betting_Score'] = (\n",
    "        betting_candidates['PRA_predicted'] * 0.5 +  # Prediction weight\n",
    "        betting_candidates['Confidence_Score'] * 30 +  # Confidence weight\n",
    "        (1 / (betting_candidates['Volatility_Score'] + 0.1)) * 5  # Inverse volatility weight\n",
    "    )\n",
    "    \n",
    "    # Categorize recommendations\n",
    "    betting_candidates['Recommendation'] = pd.cut(\n",
    "        betting_candidates['Betting_Score'],\n",
    "        bins=[0, 30, 40, 100],\n",
    "        labels=['‚ùì Consider', 'üëç Good Play', 'üî• Strong Play']\n",
    "    )\n",
    "    \n",
    "    # Create betting lines (simulated)\n",
    "    betting_candidates['Suggested_Line'] = (betting_candidates['PRA_predicted'] - 2).round(0)\n",
    "    betting_candidates['Hit_Probability'] = np.random.uniform(0.45, 0.75, len(betting_candidates))\n",
    "    \n",
    "    return betting_candidates\n",
    "\n",
    "# Generate recommendations\n",
    "betting_sheet = generate_betting_sheet(player_features)\n",
    "betting_sheet = betting_sheet.sort_values('Betting_Score', ascending=False)\n",
    "\n",
    "print(\"\\nüé∞ TODAY'S BETTING RECOMMENDATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Player':<20} {'Team':<5} {'Pred PRA':<10} {'Line':<8} {'Risk':<12} {'Rec':<15}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Show top 15 recommendations\n",
    "for _, player in betting_sheet.head(15).iterrows():\n",
    "    print(f\"{player['Player'][:19]:<20} {player['Team']:<5} \"\n",
    "          f\"{player['PRA_predicted']:>8.1f} {player['Suggested_Line']:>7.0f}u \"\n",
    "          f\"{player['Risk_Category']:<12} {player['Recommendation']}\")\n",
    "\n",
    "# Category breakdown\n",
    "print(\"\\nüìä RECOMMENDATIONS BREAKDOWN:\")\n",
    "print(\"=\"*40)\n",
    "rec_counts = betting_sheet['Recommendation'].value_counts()\n",
    "for rec, count in rec_counts.items():\n",
    "    print(f\"{rec}: {count} players\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Player Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatter plot with Plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# Prepare data for interactive plot\n",
    "plot_data = player_features.copy()\n",
    "plot_data['Player_Info'] = plot_data['Player'] + ' (' + plot_data['Team'] + ')'\n",
    "\n",
    "# Create interactive scatter plot\n",
    "fig = px.scatter(\n",
    "    plot_data,\n",
    "    x='Volatility_Score',\n",
    "    y='PRA_predicted',\n",
    "    color='Risk_Category',\n",
    "    size='MIN',\n",
    "    hover_data={\n",
    "        'Player': True,\n",
    "        'Team': True,\n",
    "        'PRA_predicted': ':.1f',\n",
    "        'Volatility_Score': ':.2f',\n",
    "        'Confidence_Score': ':.2f',\n",
    "        'MIN': ':.1f'\n",
    "    },\n",
    "    title='Interactive Player Explorer - Hover for Details',\n",
    "    labels={\n",
    "        'Volatility_Score': 'Risk Level',\n",
    "        'PRA_predicted': 'Predicted PRA',\n",
    "        'MIN': 'Minutes Played'\n",
    "    },\n",
    "    color_discrete_map={\n",
    "        'Low Risk': 'green',\n",
    "        'Medium Risk': 'orange', \n",
    "        'High Risk': 'red'\n",
    "    },\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Add quadrant lines\n",
    "fig.add_hline(y=plot_data['PRA_predicted'].median(), line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
    "fig.add_vline(x=0.5, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
    "\n",
    "# Add quadrant annotations\n",
    "fig.add_annotation(x=0.25, y=plot_data['PRA_predicted'].max()*0.95,\n",
    "                  text=\"PREMIUM PLAYS\", showarrow=False,\n",
    "                  font=dict(size=12, color=\"darkgreen\"))\n",
    "fig.add_annotation(x=0.75, y=plot_data['PRA_predicted'].max()*0.95,\n",
    "                  text=\"HIGH RISK/REWARD\", showarrow=False,\n",
    "                  font=dict(size=12, color=\"darkorange\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° TIP: Hover over any point to see player details!\")\n",
    "print(\"    - Size represents minutes played\")\n",
    "print(\"    - Color represents risk category\")\n",
    "print(\"    - Position shows risk vs reward tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find Similar Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_players(player_name, df, n_similar=5):\n",
    "    \"\"\"Find players with similar playing style and stats\"\"\"\n",
    "    \n",
    "    if player_name not in df['Player'].values:\n",
    "        print(f\"Player '{player_name}' not found in database\")\n",
    "        return None\n",
    "    \n",
    "    # Get target player\n",
    "    target = df[df['Player'] == player_name].iloc[0]\n",
    "    \n",
    "    # Calculate similarity based on key features\n",
    "    feature_cols = ['MIN', 'Usage', 'PRA_predicted']\n",
    "    if 'PSA' in df.columns:\n",
    "        feature_cols.append('PSA')\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(df[feature_cols].fillna(0))\n",
    "    target_scaled = scaler.transform(df[df['Player'] == player_name][feature_cols].fillna(0))\n",
    "    \n",
    "    # Calculate distances\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    distances = euclidean_distances(target_scaled, features_scaled)[0]\n",
    "    \n",
    "    # Get similar players\n",
    "    df['Similarity_Distance'] = distances\n",
    "    similar = df[df['Player'] != player_name].nsmallest(n_similar, 'Similarity_Distance')\n",
    "    \n",
    "    return target, similar\n",
    "\n",
    "# Example: Find players similar to a top player\n",
    "example_player = player_features.nlargest(1, 'PRA_predicted')['Player'].iloc[0]\n",
    "target, similar = find_similar_players(example_player, player_features)\n",
    "\n",
    "if similar is not None:\n",
    "    print(f\"\\nüîç PLAYERS SIMILAR TO {example_player}:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Target: {target['Player']} ({target['Team']}) - {target['PRA_predicted']:.1f} PRA\")\n",
    "    print(\"\\nSimilar Players:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for _, player in similar.iterrows():\n",
    "        print(f\"{player['Player']:20s} ({player['Team']})  ‚Üí  \"\n",
    "              f\"{player['PRA_predicted']:.1f} PRA  |  \"\n",
    "              f\"Risk: {player['Risk_Category']}  |  \"\n",
    "              f\"Similarity: {100 - player['Similarity_Distance']*10:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Betting Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final betting sheet for export\n",
    "export_columns = [\n",
    "    'Player', 'Team', 'PRA_predicted', 'Suggested_Line',\n",
    "    'Risk_Category', 'Confidence_Score', 'Recommendation'\n",
    "]\n",
    "\n",
    "final_betting_sheet = betting_sheet[export_columns].head(30)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = Path('/Users/diyagamah/Documents/nba_props_model/data/processed')\n",
    "output_file = output_path / 'betting_recommendations.csv'\n",
    "final_betting_sheet.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\nüíæ EXPORT COMPLETE:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"‚úÖ Saved top 30 betting recommendations to:\")\n",
    "print(f\"   {output_file}\")\n",
    "print(\"\\nüìã File contains:\")\n",
    "print(\"   - Player names and teams\")\n",
    "print(\"   - PRA predictions\")\n",
    "print(\"   - Suggested betting lines\")\n",
    "print(\"   - Risk categories\")\n",
    "print(\"   - Confidence scores\")\n",
    "print(\"   - Recommendations (Strong/Good/Consider)\")\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"\\nüìä SUMMARY STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average PRA Prediction: {final_betting_sheet['PRA_predicted'].mean():.1f}\")\n",
    "print(f\"Average Confidence: {final_betting_sheet['Confidence_Score'].mean():.2%}\")\n",
    "print(f\"Risk Distribution:\")\n",
    "for risk, count in final_betting_sheet['Risk_Category'].value_counts().items():\n",
    "    print(f\"  - {risk}: {count} players\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways & Action Items\n",
    "\n",
    "### üéØ What You've Learned:\n",
    "1. **Top PRA Players**: Identified highest projected players for targeting overs\n",
    "2. **Risk Assessment**: Quantified volatility for each player\n",
    "3. **Player Archetypes**: Discovered 5 distinct player types\n",
    "4. **Betting Targets**: Found premium low-risk, high-reward plays\n",
    "5. **Similar Players**: Can find comparable players for benchmarking\n",
    "\n",
    "### üìã Action Items:\n",
    "1. **Review Premium Plays**: Focus on low-risk, high-PRA players\n",
    "2. **Check Betting Lines**: Compare predictions to actual bookmaker lines\n",
    "3. **Monitor Volatility**: Avoid high-volatility players for consistent wins\n",
    "4. **Track Performance**: Record actual results to improve model\n",
    "5. **Daily Updates**: Re-run with latest data for current predictions\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Add game-by-game data for better temporal features\n",
    "2. Include opponent defensive ratings\n",
    "3. Add injury reports and lineup changes\n",
    "4. Backtest against historical betting lines\n",
    "5. Create automated daily prediction pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-props-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
